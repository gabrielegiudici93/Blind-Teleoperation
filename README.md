# Leveraging Tactile Sensing to Render both Haptic Feedback and Virtual Reality 3D Object Reconstruction in Robotic Telemanipulation


<details>
<summary><strong><em> PAPER WEBSITE:</em></strong></summary>

<div style="background-color: #f2f2f2; padding: 10px;">
https://gabrielegiudici93.github.io/Blind-Teleoperation/
</div>
</details>

<details>
<summary><strong><em>ABSTRACT:</em></strong></summary>

<div style="background-color: #f2f2f2; padding: 10px; text-align: justify;">
Dexterous robotic manipulator teleoperation is widely used in many applications, either where it is convenient to keep the human inside the control loop, or to train advanced robot agents. So far, this technology has been used in combination with camera systems with remarkable success. On the other hand, only a limited number of studies have focused on leveraging the haptic feedback from tactile sensors with in those contexts where camera based system fail e.g. due to self-occlusions or poor light conditions such as due to smoke. In this study, we demonstrate the feasibility of accomplishing precise pick-and-place teleoperation tasks without the use of cameras by conducting experiments in real-world scenarios for a blindfolded user wearing a virtual reality (VR) headset. This is achieved by leveraging the capabilities offered by tactile sensors to reconstruct objects in VR and provide haptic feedback to the human teleoperator's hand.



</details>

</div>
</details>
